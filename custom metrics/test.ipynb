{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "def get_api(url):\n",
    "    import google.auth\n",
    "    credentials, project = google.auth.default()\n",
    "    from google.auth.transport.requests import AuthorizedSession\n",
    "    authed_session = AuthorizedSession(credentials)\n",
    "    response = authed_session.get(url)\n",
    "    return response\n",
    "\n",
    "def post_api(url, data):\n",
    "    import google.auth\n",
    "    credentials, project = google.auth.default()\n",
    "    from google.auth.transport.requests import AuthorizedSession\n",
    "    authed_session = AuthorizedSession(credentials)\n",
    "    response = authed_session.post(url, data)\n",
    "    return response\n",
    "\n",
    "def get_createdby(createTime, jobId):\n",
    "    createdBy=\"\"\n",
    "    import arrow\n",
    "    createTime = arrow.get(createTime)\n",
    "    logstart=createTime + datetime.timedelta(minutes = -2)\n",
    "    logend=createTime + datetime.timedelta(minutes = 2)\n",
    "    body = {\"resourceNames\": [\"projects/sb-bigdata-4985-da852265\"], \"filter\":'resource.type=\"audited_resource\" \\\n",
    "    resource.labels.service=\"ml.googleapis.com\" \\\n",
    "    resource.labels.method=\"google.cloud.ml.v1.JobService.CreateJob\" \\\n",
    "    timestamp>=\"' + str(logstart) + '\" \\\n",
    "    timestamp<=\"' + str(logend) + '\"'\n",
    "    }\n",
    "    y = json.dumps(body)\n",
    "    response=post_api('https://logging.googleapis.com/v2/entries:list', y)\n",
    "    import pandas as pd\n",
    "    data_df = pd.read_json(response.text)\n",
    "    if 'entries' in data_df:\n",
    "        for job in data_df['entries']:\n",
    "            if job[\"protoPayload\"][\"request\"][\"job\"][\"jobId\"] == jobId:\n",
    "                createdBy=job[\"protoPayload\"][\"authenticationInfo\"][\"principalEmail\"]\n",
    "                break\n",
    "    else:\n",
    "        if response.status_code == 429:\n",
    "            import time\n",
    "            # print(\"Sleeping 1 Sec: \" + jobId)\n",
    "            time.sleep(1)\n",
    "            createdBy=get_createdby(createTime, jobId)\n",
    "            #createdBy=\"Error\"\n",
    "            \n",
    "    return createdBy\n",
    "    \n",
    "def get_trainingcost(consumedMLUnits):\n",
    "    trainingCost=\"\"\n",
    "    import arrow\n",
    "    trainingCost = arrow.get(trainingOutput.consumedMLUnits)\n",
    "    logstart=datetime.timedelta(minutes = -2)\n",
    "    logend=datetime.timedelta(minutes = 2)\n",
    "    body = {\"resourceNames\": [\"projects/sb-bigdata-4985-da852265\"], \"filter\":'resource.type=\"audited_resource\" \\\n",
    "    resource.labels.service=\"ml.googleapis.com\" \\\n",
    "    resource.labels.method=\"google.cloud.ml.v1.JobService.CreateJob\" \\\n",
    "    timestamp>=\"' + str(logstart) + '\" \\\n",
    "    timestamp<=\"' + str(logend) + '\"'\n",
    "    }\n",
    "    x = json.dumps(body)\n",
    "    response=post_api('https://logging.googleapis.com/v2/entries:list', x)\n",
    "    import pandas as pd\n",
    "    data_df = pd.read_json(response.text)\n",
    "    for job in data_df['entries']:\n",
    "        trainingCost = trainingCost*0.49\n",
    "            \n",
    "    return trainingCost   \n",
    "    \n",
    "def get_jobs_df():\n",
    "    response = get_api('https://ml.googleapis.com/v1/projects/sb-bigdata-4985-da852265/jobs')\n",
    "    job_list=[]\n",
    "    if response.status_code == 200:\n",
    "        while True:\n",
    "            import json\n",
    "            import pandas as pd\n",
    "            data_df = pd.read_json(response.text)\n",
    "            for job in data_df['jobs']:\n",
    "                job[\"createdby\"]=get_createdby(job[\"createTime\"], job[\"jobId\"])\n",
    "                #job[\"trainingcost\"]=get_trainingcost(job[\"consumedMLUnits\"])\n",
    "                job_list.append(job)\n",
    "                \n",
    "            page_token = None\n",
    "            page_token = data_df.get('nextPageToken')\n",
    "            if page_token is None:\n",
    "                break\n",
    "            else:\n",
    "                response = get_api('https://ml.googleapis.com/v1/projects/sb-bigdata-4985-da852265/jobs' + '?pageToken=' + str(page_token[0]))\n",
    "    from pandas.io.json import json_normalize\n",
    "    job_df=json_normalize(job_list)\n",
    "    job_df_new = job_df.rename(columns={\"createTime\": \"createtime\", \"endTime\": \"endtime\", \"jobId\":\"jobid\", \"startTime\":\"starttime\"\n",
    "                       , \"trainingInput.args\":\"args\", \"trainingInput.jobDir\":\"jobdir\", \"trainingInput.masterConfig.imageUri\":\"imageuri\"\n",
    "                       , \"trainingInput.masterType\":\"mastertype\", \"trainingInput.packageUris\":\"packageuris\", \"trainingInput.pythonModule\":\"pythonmodule\"\n",
    "                       , \"trainingInput.pythonVersion\":\"pythonversion\", \"trainingInput.region\":\"region\", \"trainingInput.runtimeVersion\":\"runtimeversion\"\n",
    "                       , \"trainingInput.scaleTier\":\"scaletier\", \"trainingOutput.consumedMLUnits\":\"consumedmlunits\", \"trainingCost\":\"trainingcost\"})\n",
    "    return job_df_new\n",
    "\n",
    "def write_to_bqtable(bq_tablename, bq_schemaname, datadf):\n",
    "    import google.auth\n",
    "    from google.cloud import bigquery\n",
    "    credentials, project = google.auth.default()\n",
    "    client = bigquery.Client(project)\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    job_config.schema = bq_schemaname\n",
    "    \n",
    "    job = client.load_table_from_dataframe(datadf, bq_tablename, job_config=job_config)\n",
    "    # Wait for the load job to complete.\n",
    "    job.result()\n",
    "\n",
    "def get_data(request): \n",
    "    jobs = []\n",
    "    jobs = get_jobs_df()\n",
    "    jobs = jobs.drop(columns=[\"errorMessage\", \"etag\"])\n",
    "    print(\"AI platform jobs count : \",str(len(jobs)))\n",
    "    jobs.insert(0, 'date', str(datetime.datetime.utcnow()))\n",
    "    from google.cloud import bigquery\n",
    "    varbqschema=[\n",
    "        bigquery.SchemaField(name=\"date\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"createtime\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"createdby\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"endtime\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"jobid\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"starttime\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"state\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"args\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"jobdir\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"imageuri\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"mastertype\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"packageuris\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"pythonmodule\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"pythonversion\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"region\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"runtimeversion\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"scaletier\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"consumedmlunits\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"trainingcost\", field_type=\"STRING\")\n",
    "    ]\n",
    "    write_to_bqtable('modelmanagement.jobstemp', varbqschema, jobs.astype(str))\n",
    "    return \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-09 14:07:53.942324\n",
      "AI platform jobs count :  827\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "bq_schema contains fields not present in dataframe: {'trainingcost'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-bf4fdb3f8bc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-12ccaf98d41e>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSchemaField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"trainingcost\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"STRING\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     ]\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mwrite_to_bqtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'modelmanagement.jobstemp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvarbqschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-12ccaf98d41e>\u001b[0m in \u001b[0;36mwrite_to_bqtable\u001b[0;34m(bq_tablename, bq_schemaname, datadf)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mjob_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbq_schemaname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_table_from_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatadf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbq_tablename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Wait for the load job to complete.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36mload_table_from_dataframe\u001b[0;34m(self, dataframe, destination, num_retries, job_id, job_id_prefix, location, project, job_config, parquet_compression)\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1574\u001b[0m         job_config.schema = _pandas_helpers.dataframe_to_bq_schema(\n\u001b[0;32m-> 1575\u001b[0;31m             \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1576\u001b[0m         )\n\u001b[1;32m   1577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/_pandas_helpers.py\u001b[0m in \u001b[0;36mdataframe_to_bq_schema\u001b[0;34m(dataframe, bq_schema)\u001b[0m\n\u001b[1;32m    283\u001b[0m         raise ValueError(\n\u001b[1;32m    284\u001b[0m             u\"bq_schema contains fields not present in dataframe: {}\".format(\n\u001b[0;32m--> 285\u001b[0;31m                 \u001b[0mbq_schema_unused\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             )\n\u001b[1;32m    287\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: bq_schema contains fields not present in dataframe: {'trainingcost'}"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "get_data(None)\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobs_df():\n",
    "    response = get_api('https://ml.googleapis.com/v1/projects/sb-bigdata-4985-da852265/jobs')\n",
    "    job_list=[]\n",
    "    if response.status_code == 200:\n",
    "        while True:\n",
    "            import json\n",
    "            import pandas as pd\n",
    "            data_df = pd.read_json(response.text)\n",
    "            for job in data_df['jobs']:\n",
    "                job[\"createdby\"]=get_createdby(job[\"createTime\"], job[\"jobId\"])\n",
    "                job_list.append(job)\n",
    "                \n",
    "            page_token = None\n",
    "            page_token = data_df.get('nextPageToken')\n",
    "            if page_token is None:\n",
    "                break\n",
    "            else:\n",
    "                response = get_api('https://ml.googleapis.com/v1/projects/sb-bigdata-4985-da852265/jobs' + '?pageToken=' + str(page_token[0]))\n",
    "    from pandas.io.json import json_normalize\n",
    "    job_df=json_normalize(job_list)\n",
    "    job_df_new = job_df.rename(columns={\"createTime\": \"createtime\", \"endTime\": \"endtime\", \"jobId\":\"jobid\", \"startTime\":\"starttime\"\n",
    "                       , \"trainingInput.args\":\"args\", \"trainingInput.jobDir\":\"jobdir\", \"trainingInput.masterConfig.imageUri\":\"imageuri\"\n",
    "                       , \"trainingInput.masterType\":\"mastertype\", \"trainingInput.packageUris\":\"packageuris\", \"trainingInput.pythonModule\":\"pythonmodule\"\n",
    "                       , \"trainingInput.pythonVersion\":\"pythonversion\", \"trainingInput.region\":\"region\", \"trainingInput.runtimeVersion\":\"runtimeversion\"\n",
    "                       , \"trainingInput.scaleTier\":\"scaletier\", \"trainingOutput.consumedMLUnits\":\"consumedmlunits\"})\n",
    "    return job_df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_api('https://ml.googleapis.com/v1/projects/sb-bigdata-4985-da852265/jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'consumedMLUnits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-cb0b0f0136eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainingCost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconsumedMLUnits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'consumedMLUnits' is not defined"
     ]
    }
   ],
   "source": [
    "import arrow\n",
    "trainingCost = arrow.get(consumedMLUnits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
