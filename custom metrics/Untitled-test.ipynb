{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import datetime\n",
    "import json\n",
    "import google.auth\n",
    "import arrow\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from pandas.io.json import json_normalize\n",
    "import google.auth\n",
    "from google.cloud import bigquery\n",
    "from google.auth.transport.requests import AuthorizedSession\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_api(url):\n",
    "    import google.auth\n",
    "    credentials, project = google.auth.default()\n",
    "    from google.auth.transport.requests import AuthorizedSession\n",
    "    authed_session = AuthorizedSession(credentials)\n",
    "    response = authed_session.get(url)\n",
    "    return response\n",
    "\n",
    "def post_api(url, data):\n",
    "    import google.auth\n",
    "    credentials, project = google.auth.default()\n",
    "    from google.auth.transport.requests import AuthorizedSession\n",
    "    authed_session = AuthorizedSession(credentials)\n",
    "    response = authed_session.post(url, data)\n",
    "    return response\n",
    "\n",
    "def get_createdby(createTime, jobId):\n",
    "    createdBy=\"NA\"\n",
    "    import arrow\n",
    "    import json\n",
    "    createTime = arrow.get(createTime)\n",
    "    logstart=createTime + datetime.timedelta(minutes = -2)\n",
    "    logend=createTime + datetime.timedelta(minutes = 2)\n",
    "    body = {\"resourceNames\": [\"projects/sb-bigdata-4985-da852265\"], \"filter\":'resource.type=\"audited_resource\" \\\n",
    "    resource.labels.service=\"ml.googleapis.com\" \\\n",
    "    resource.labels.method=\"google.cloud.ml.v1.JobService.CreateJob\" \\\n",
    "    timestamp>=\"' + str(logstart) + '\" \\\n",
    "    timestamp<=\"' + str(logend) + '\"'\n",
    "    }\n",
    "    y = json.dumps(body)\n",
    "    response=post_api('https://logging.googleapis.com/v2/entries:list', y)\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    data_df = pd.read_json(response.text)\n",
    "    if 'entries' in data_df:\n",
    "        for job in data_df['entries']:\n",
    "            if job[\"protoPayload\"][\"request\"][\"job\"][\"jobId\"] == jobId:\n",
    "                createdBy=job[\"protoPayload\"][\"authenticationInfo\"][\"principalEmail\"]\n",
    "                break\n",
    "    else:\n",
    "        if response.status_code == 429:\n",
    "            import time\n",
    "            # print(\"Sleeping 1 Sec: \" + jobId)\n",
    "            time.sleep(1)\n",
    "            createdBy=get_createdby(createTime, jobId)\n",
    "            #createdBy=\"Error\"\n",
    "            \n",
    "    return createdBy\n",
    "\n",
    "def get_labels_df(createTime, jobId):\n",
    "    labels=\"NA\"\n",
    "    import arrow\n",
    "    import pandas as pd\n",
    "    createTime = arrow.get(createTime)\n",
    "    logstart=createTime + datetime.timedelta(minutes = -2)\n",
    "    logend=createTime + datetime.timedelta(minutes = 2)\n",
    "    body = {\"resourceNames\": [\"projects/sb-bigdata-4985-da852265\"], \"filter\":'resource.type=\"audited_resource\" \\\n",
    "    resource.labels.service=\"ml.googleapis.com\" \\\n",
    "    resource.labels.method=\"google.cloud.ml.v1.JobService.CreateJob\" \\\n",
    "    timestamp>=\"' + str(logstart) + '\" \\\n",
    "    timestamp<=\"' + str(logend) + '\"'\n",
    "    }\n",
    "    y = json.dumps(body)\n",
    "    response=post_api('https://logging.googleapis.com/v2/entries:list', y)\n",
    "    data_df = pd.read_json(response.text)\n",
    "    if 'entries' in data_df:\n",
    "        for job in data_df['entries']:\n",
    "            if job[\"protoPayload\"][\"request\"][\"job\"][\"jobId\"] == jobId and \"labels\" in job[\"protoPayload\"][\"request\"][\"job\"]:\n",
    "                labels=job[\"protoPayload\"][\"request\"][\"job\"][\"labels\"]\n",
    "                break\n",
    "    else:\n",
    "        if response.status_code == 429:\n",
    "            import time\n",
    "            # print(\"Sleeping 1 Sec: \" + jobId)\n",
    "            time.sleep(1)\n",
    "            labels=get_labels_df(createTime, jobId)\n",
    "    return labels\n",
    "\n",
    "def get_cost(jobId):\n",
    "    cost=\"NA\"\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    response = get_api('https://ml.googleapis.com/v1/projects/sb-bigdata-4985-da852265/jobs/')\n",
    "    data_df = pd.read_json(response.text)\n",
    "    for i in range(len(data_df['jobs'])):\n",
    "        if data_df['jobs'][i]['jobId'] == jobId:\n",
    "            cost = 0.49 * (data_df['jobs'][i]['trainingOutput']['consumedMLUnits'])\n",
    "            break\n",
    "    return cost\n",
    "\n",
    "def get_trainingStartTime(createTime, job_Id):\n",
    "    trainingStartTime=\"NA\"\n",
    "    import arrow\n",
    "    createTime = arrow.get(createTime)\n",
    "    logstart=createTime + datetime.timedelta(minutes = -2)\n",
    "    logend=createTime + datetime.timedelta(minutes = 2)\n",
    "    body = {\"resourceNames\": [\"projects/sb-bigdata-4985-da852265\"], \"filter\":'resource.labels.task_name=\"master-replica-0\" \\\n",
    "    Running task with arguments \\\n",
    "    timestamp>=\"' + str(logstart) + '\" \\\n",
    "    timestamp<=\"' + str(logend) + '\"'\n",
    "    }\n",
    "    y = json.dumps(body)\n",
    "    response=post_api('https://logging.googleapis.com/v2/entries:list', y)\n",
    "    import pandas as pd\n",
    "    data_df = pd.read_json(response.text)\n",
    "    if 'entries' in data_df:\n",
    "        for i in range(len(data_df['entries'])):\n",
    "            if data_df['entries'][i]['resource']['labels']['job_id'] == job_Id:\n",
    "                st = data_df['entries'][i]['timestamp']\n",
    "                # slice the timestamp to remove letters - T and Z. Also format the timestamp.\n",
    "                sliceA = st[:10]\n",
    "                startdate=datetime.datetime.strptime(sliceA, '%Y-%m-%d').strftime('%m%d%y')\n",
    "                sliceB = st[11:26] \n",
    "                starttime=datetime.datetime.strptime(sliceB, '%H:%M:%S.%f').strftime('%H%M%S%f')\n",
    "                # concatenate the sliced date and time segments\n",
    "                concat1 = startdate + starttime\n",
    "                # format the string of timestamp\n",
    "                trainingStartTime_str=datetime.datetime.strptime(concat1, '%m%d%y%H%M%S%f').strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "                # convert string to datetime object \n",
    "                trainingStartTime=datetime.datetime.strptime(trainingStartTime_str, '%Y-%m-%d %H:%M:%S.%f')\n",
    "                break\n",
    "    else:\n",
    "        if response.status_code == 429:\n",
    "            import time\n",
    "            # print(\"Sleeping 1 Sec: \" + jobId)\n",
    "            time.sleep(1)\n",
    "            trainingStartTime=get_trainingStartTime(createTime, job_Id)\n",
    "    return trainingStartTime\n",
    "\n",
    "# def get_trainingEndTime(createTime, job_Id):\n",
    "#     trainingEndTime=\"NA\"\n",
    "#     import arrow\n",
    "#     createTime = arrow.get(createTime)\n",
    "#     logstart=createTime + datetime.timedelta(minutes = -2)\n",
    "#     logend=createTime + datetime.timedelta(minutes = 2)\n",
    "#     body = {\"resourceNames\": [\"projects/sb-bigdata-4985-da852265\"], \"filter\":'resource.labels.task_name=\"master-replica-0\" \\\n",
    "#     Module completed cleaning up \\\n",
    "#     timestamp>=\"' + str(logstart) + '\" \\\n",
    "#     timestamp<=\"' + str(logend) + '\"'\n",
    "#     }\n",
    "#     y = json.dumps(body)\n",
    "#     response=post_api('https://logging.googleapis.com/v2/entries:list', y)\n",
    "#     import pandas as pd\n",
    "#     data_df = pd.read_json(response.text)\n",
    "#     if 'entries' in data_df:\n",
    "#         for i in range(len(data_df['entries'])):\n",
    "#             if data_df['entries'][i]['resource']['labels']['job_id'] == job_Id:\n",
    "#                 et = data_df['entries'][i]['timestamp']\n",
    "#                 # slice the timestamp to remove letters - T and Z. Also format the timestamp.\n",
    "#                 sliceC = et[:10]\n",
    "#                 enddate=datetime.datetime.strptime(sliceC, '%Y-%m-%d').strftime('%m%d%y')\n",
    "#                 sliceD = et[11:26]\n",
    "#                 endtime=datetime.datetime.strptime(sliceD, '%H:%M:%S.%f').strftime('%H%M%S%f')\n",
    "#                 # concatenate the sliced date and time segments\n",
    "#                 concat2 = enddate + endtime\n",
    "#                 # format the string of timestamp\n",
    "#                 trainingEndTime_str=datetime.datetime.strptime(concat2, '%m%d%y%H%M%S%f').strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "#                 # convert string to datetime object \n",
    "#                 trainingEndTime=datetime.datetime.strptime(trainingEndTime_str, '%Y-%m-%d %H:%M:%S.%f')\n",
    "#                 break   \n",
    "#     else:\n",
    "#         if response.status_code == 429:\n",
    "#             import time\n",
    "#             # print(\"Sleeping 1 Sec: \" + jobId)\n",
    "#             time.sleep(1)\n",
    "#             trainingEndTime=get_trainingEndTime(createTime, job_Id)\n",
    "#     return trainingEndTime\n",
    "\n",
    "#resource.labels.job_id=\"census_training_1576841019\" timestamp>=\"2019-12-20T11:23:43Z\"\n",
    "# resource.labels.job_id=\"sentiment_py3_basic_TPU_resolver_20191220_143926\" \n",
    "# jsonPayload.message=\"Module completed; cleaning up.\"\n",
    "\n",
    "def get_trainingEndTime(createTime, job_Id):\n",
    "    #print(\"START get_trainingEndTime.....\")\n",
    "    trainingEndTime=\"NA\"\n",
    "    page_token = ''\n",
    "    createTime = arrow.get(createTime)\n",
    "  \n",
    "    filter_str = 'resource.labels.job_id=\"' + str(job_Id) + '\" \\\n",
    "    jsonPayload.message=\"Module completed; cleaning up.\"'\n",
    "    body = {\"resourceNames\": [\"projects/sb-bigdata-4985-da852265\"],\"pageToken\" :str(page_token), \"filter\":filter_str }\n",
    "    #print(body)\n",
    "    y = json.dumps(body)\n",
    "    response=post_api('https://logging.googleapis.com/v2/entries:list', y)\n",
    "    #print(response.text)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        \n",
    "        while True:\n",
    "            data_df = pd.read_json(response.text, typ='series')\n",
    "            #if 'entries' in data_df:\n",
    "                #\n",
    "                #for i in range(len(data_df['entries'])):\n",
    "            if 'entries' in data_df and data_df['entries'][0]['resource']['labels']['job_id'] == job_Id:\n",
    "                et = data_df['entries'][0]['timestamp']\n",
    "                # slice the timestamp to remove letters - T and Z. Also format the timestamp.\n",
    "                sliceC = et[:10]\n",
    "                enddate=datetime.datetime.strptime(sliceC, '%Y-%m-%d').strftime('%m%d%y')\n",
    "                sliceD = et[11:26]\n",
    "                endtime=datetime.datetime.strptime(sliceD, '%H:%M:%S.%f').strftime('%H%M%S%f')\n",
    "                # concatenate the sliced date and time segments\n",
    "                concat2 = enddate + endtime\n",
    "                # format the string of timestamp\n",
    "                trainingEndTime_str=datetime.datetime.strptime(concat2, '%m%d%y%H%M%S%f').strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "                # convert string to datetime object \n",
    "                trainingEndTime=datetime.datetime.strptime(trainingEndTime_str, '%Y-%m-%d %H:%M:%S.%f')\n",
    "                #print(\"in main -->endtime for job_id {}. is {}.\".format(job_Id ,trainingEndTime))\n",
    "                break   \n",
    "            #     \n",
    "            else:\n",
    "                #\n",
    "                page_token = None\n",
    "                page_token = data_df.get('nextPageToken')\n",
    "                if page_token is None:\n",
    "                    break\n",
    "                else:\n",
    "                    #\n",
    "                    #print(\"****pagetoken recieved*****\")\n",
    "                    body = {\"resourceNames\": [\"projects/sb-bigdata-4985-da852265\"],\"pageToken\" :str(page_token), \"filter\":filter_str }\n",
    "                    y = json.dumps(body)\n",
    "                    response = post_api('https://logging.googleapis.com/v2/entries:list', y)\n",
    "\n",
    "#    print(\"END get_trainingEndTime ... \")\n",
    "    return trainingEndTime\n",
    "    \n",
    "def get_jobs_df():\n",
    "    response = get_api('https://ml.googleapis.com/v1/projects/sb-bigdata-4985-da852265/jobs')\n",
    "    job_list=[]\n",
    "    i = 0\n",
    "    if response.status_code == 200:\n",
    "        import json\n",
    "        import pandas as pd\n",
    "        data_df = pd.read_json(response.text)\n",
    "        #while True:\n",
    "        for job in data_df['jobs']:\n",
    "            if job['createTime'] >= max(job['createTime']):\n",
    "                #job[\"trainingStartTime\"]=get_trainingStartTime(job[\"createTime\"], job[\"jobId\"])\n",
    "                job[\"trainingEndTime\"]=get_trainingEndTime(job[\"createTime\"], job[\"jobId\"])\n",
    "                job[\"createdby\"]=get_createdby(job[\"createTime\"], job[\"jobId\"])\n",
    "                job[\"labels\"]=[get_labels_df(job[\"createTime\"], job[\"jobId\"])]\n",
    "                job[\"trainingCost\"]=get_cost(job[\"jobId\"])\n",
    "                job_list.append(job)\n",
    "                i += 1\n",
    "                print(i)\n",
    "                page_token = None\n",
    "                page_token = data_df.get('nextPageToken')\n",
    "                if page_token is None:\n",
    "                    break\n",
    "                else:\n",
    "                    response = get_api('https://ml.googleapis.com/v1/projects/sb-bigdata-4985-da852265/jobs' + '?pageToken=' + str(page_token[0]))\n",
    "            else:\n",
    "                None\n",
    "    from pandas.io.json import json_normalize\n",
    "    job_df=json_normalize(job_list)\n",
    "    #print(job_df)\n",
    "    job_df_new = job_df.rename(columns={\"createTime\": \"createtime\", \"endTime\": \"endtime\", \"jobId\":\"jobid\", \"startTime\":\"starttime\"\n",
    "                       , \"trainingInput.args\":\"args\", \"trainingInput.jobDir\":\"jobdir\", \"trainingInput.masterConfig.imageUri\":\"imageuri\"\n",
    "                       , \"trainingInput.masterType\":\"mastertype\", \"trainingInput.packageUris\":\"packageuris\", \"trainingInput.pythonModule\":\"pythonmodule\"\n",
    "                       , \"trainingInput.pythonVersion\":\"pythonversion\", \"trainingInput.region\":\"region\", \"trainingInput.runtimeVersion\":\"runtimeversion\"\n",
    "                       , \"trainingInput.scaleTier\":\"scaletier\", \"trainingOutput.consumedMLUnits\":\"consumedmlunits\", \"labels\":\"label\"\n",
    "                       , \"trainingInput.masterConfig.acceleratorConfig.count\":\"acceleratorconfigcount\"\n",
    "                       , \"trainingInput.masterConfig.acceleratorConfig.type\":\"acceleratorconfigtype\", \"trainingCost\":\"trainingcost\"\n",
    "                       , \"trainingEndTime\":\"trainingendtime\"})\n",
    "    return job_df_new\n",
    "\n",
    "def write_to_bqtable(bq_tablename, bq_schemaname, datadf):\n",
    "    import google.auth\n",
    "    from google.cloud import bigquery\n",
    "    credentials, project = google.auth.default()\n",
    "    client = bigquery.Client(project)\n",
    "    job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
    "    job_config.schema = bq_schemaname\n",
    "    \n",
    "    job = client.load_table_from_dataframe(datadf, bq_tablename, job_config=job_config)\n",
    "    # Wait for the load job to complete.\n",
    "    job.result()\n",
    "\n",
    "def get_data(request):\n",
    "    jobs = []\n",
    "    jobs = get_jobs_df()\n",
    "    jobs = jobs.drop(columns=[\"errorMessage\", \"etag\"])\n",
    "    print(\"AI platform jobs count : \",str(len(jobs)))\n",
    "    jobs.insert(0, 'date', str(datetime.datetime.utcnow()))\n",
    "    from google.cloud import bigquery\n",
    "    varbqschema=[\n",
    "        bigquery.SchemaField(name=\"date\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"createtime\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"createdby\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"endtime\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"jobid\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"starttime\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"state\", field_type=\"STRING\"),\n",
    "        #bigquery.SchemaField(name=\"args\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"jobdir\", field_type=\"STRING\"),\n",
    "        #bigquery.SchemaField(name=\"imageuri\", field_type=\"STRING\"),\n",
    "        #bigquery.SchemaField(name=\"mastertype\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"packageuris\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"pythonmodule\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"pythonversion\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"region\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"runtimeversion\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"scaletier\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"consumedmlunits\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"label\", field_type=\"STRING\"),\n",
    "        #bigquery.SchemaField(name=\"acceleratorconfigcount\", field_type=\"STRING\"),\n",
    "        #bigquery.SchemaField(name=\"acceleratorconfigtype\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"trainingcost\", field_type=\"STRING\"),\n",
    "        #bigquery.SchemaField(name=\"trainingstarttime\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"trainingendtime\", field_type=\"STRING\")\n",
    "    ]\n",
    "    write_to_bqtable('modelmanagement.jobmetrics', varbqschema, jobs.astype(str))\n",
    "    return \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     remove_cols = pd.DataFrame(columns=['errorMessage', 'etag'])\n",
    "#     for col in remove_cols.columns:\n",
    "#         if col in jobs.columns:\n",
    "#             jobs = jobs.drop(col, 1)\n",
    "#         else:\n",
    "#             None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
