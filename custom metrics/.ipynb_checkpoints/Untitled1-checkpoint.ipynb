{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized empty Git repository in /home/jupyter/.git/\n"
     ]
    }
   ],
   "source": [
    "# Setup Git\n",
    "!git init\n",
    "!git remote add origin https://dev.azure.com/accenturecio04/AnalyticsPlatform_4985/_git/cap-modelmanager-gcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import datetime\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "def get_api(url):\n",
    "    import google.auth\n",
    "    credentials, project = google.auth.default()\n",
    "    from google.auth.transport.requests import AuthorizedSession\n",
    "    authed_session = AuthorizedSession(credentials)\n",
    "    response = authed_session.get(url)\n",
    "    return response\n",
    "\n",
    "def post_api(url, data):\n",
    "    import google.auth\n",
    "    credentials, project = google.auth.default()\n",
    "    from google.auth.transport.requests import AuthorizedSession\n",
    "    authed_session = AuthorizedSession(credentials)\n",
    "    response = authed_session.post(url, data)\n",
    "    return response\n",
    "\n",
    "def get_createdby(createTime, jobId):\n",
    "    createdBy=\"\"\n",
    "    import arrow\n",
    "    createTime = arrow.get(createTime)\n",
    "    logstart=createTime + datetime.timedelta(minutes = -2)\n",
    "    logend=createTime + datetime.timedelta(minutes = 2)\n",
    "    body = {\"resourceNames\": [\"projects/sb-bigdata-4985-da852265\"], \"filter\":'resource.type=\"audited_resource\" \\\n",
    "    resource.labels.service=\"ml.googleapis.com\" \\\n",
    "    resource.labels.method=\"google.cloud.ml.v1.JobService.CreateJob\" \\\n",
    "    timestamp>=\"' + str(logstart) + '\" \\\n",
    "    timestamp<=\"' + str(logend) + '\"'\n",
    "    }\n",
    "    y = json.dumps(body)\n",
    "    response=post_api('https://logging.googleapis.com/v2/entries:list', y)\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    data_df = pd.read_json(response.text)\n",
    "    if 'entries' in data_df:\n",
    "        for job in data_df['entries']:\n",
    "            if job[\"protoPayload\"][\"request\"][\"job\"][\"jobId\"] == jobId:\n",
    "                createdBy=job[\"protoPayload\"][\"authenticationInfo\"][\"principalEmail\"]\n",
    "                break\n",
    "    else:\n",
    "        if response.status_code == 429:\n",
    "            import time\n",
    "            # print(\"Sleeping 1 Sec: \" + jobId)\n",
    "            time.sleep(1)\n",
    "            createdBy=get_createdby(createTime, jobId)\n",
    "            #createdBy=\"Error\"\n",
    "            \n",
    "    return createdBy\n",
    "\n",
    "def get_labels_df(createTime, jobId):    \n",
    "    labels=\"\"\n",
    "    import arrow\n",
    "    createTime = arrow.get(createTime)\n",
    "    logstart=createTime + datetime.timedelta(minutes = -2)\n",
    "    logend=createTime + datetime.timedelta(minutes = 2)\n",
    "    body = {\"resourceNames\": [\"projects/sb-bigdata-4985-da852265\"], \"filter\":'resource.type=\"audited_resource\" \\\n",
    "    resource.labels.service=\"ml.googleapis.com\" \\\n",
    "    resource.labels.method=\"google.cloud.ml.v1.JobService.CreateJob\" \\\n",
    "    timestamp>=\"' + str(logstart) + '\" \\\n",
    "    timestamp<=\"' + str(logend) + '\"'\n",
    "    }\n",
    "    y = json.dumps(body)\n",
    "    response=post_api('https://logging.googleapis.com/v2/entries:list', y)\n",
    "    data_df = pd.read_json(response.text)\n",
    "    if 'entries' in data_df:\n",
    "        for job in data_df['entries']:\n",
    "            if job[\"protoPayload\"][\"request\"][\"job\"][\"jobId\"] == jobId and \"labels\" in job[\"protoPayload\"][\"request\"][\"job\"]:\n",
    "                labels=job[\"protoPayload\"][\"request\"][\"job\"][\"labels\"]\n",
    "                break\n",
    "    else:\n",
    "        if response.status_code == 429:\n",
    "            import time\n",
    "            # print(\"Sleeping 1 Sec: \" + jobId)\n",
    "            time.sleep(1)\n",
    "            labels=get_labels_df(createTime, jobId)\n",
    "            \n",
    "    return labels\n",
    "\n",
    "def get_cost(jobId):\n",
    "    cost=\"NA\"\n",
    "    response = get_api('https://ml.googleapis.com/v1/projects/sb-bigdata-4985-da852265/jobs')\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    data_df = pd.read_json(response.text)\n",
    "    #print(data_df['jobs'])\n",
    "    for i in range(len(data_df['jobs'])):\n",
    "        if data_df['jobs'][i]['jobId'] == jobId:\n",
    "            cost = 0.49 * (data_df['jobs'][i]['trainingOutput']['consumedMLUnits'])\n",
    "            break\n",
    "    return cost\n",
    "\n",
    "def get_trainingStartTime(job_Id):\n",
    "    trainingStartTime=\"\"\n",
    "    body = {\"resourceNames\": [\"projects/sb-bigdata-4985-da852265\"], \"filter\":'resource.labels.task_name=\"master-replica-0\" \\\n",
    "    timestamp>=\"2019-12-12T12:43:44Z\" \\\n",
    "    Running task with arguments'\n",
    "    }\n",
    "    y = json.dumps(body)\n",
    "    response=post_api('https://logging.googleapis.com/v2/entries:list', y)\n",
    "    import pandas as pd\n",
    "    data_df = pd.read_json(response.text)\n",
    "    if 'entries' in data_df:\n",
    "        for i in range(len(data_df['entries'])):\n",
    "            if data_df['entries'][i]['resource']['labels']['job_id'] == job_Id:\n",
    "                st = data_df['entries'][i]['timestamp']\n",
    "                # slice the timestamp to remove letters - T and Z. Also format the timestamp.\n",
    "                sliceA = st[:10]\n",
    "                startdate=datetime.datetime.strptime(sliceA, '%Y-%m-%d').strftime('%m%d%y')\n",
    "                sliceB = st[11:26]\n",
    "                starttime=datetime.datetime.strptime(sliceB, '%H:%M:%S.%f').strftime('%H%M%S%f')\n",
    "                # concatenate the sliced date and time segments\n",
    "                concat1 = startdate + starttime\n",
    "                # format the string of timestamp\n",
    "                trainingStartTime_str=datetime.datetime.strptime(concat1, '%m%d%y%H%M%S%f').strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "                # convert string to datetime object \n",
    "                trainingStartTime=datetime.datetime.strptime(trainingStartTime_str, '%Y-%m-%d %H:%M:%S.%f')\n",
    "                break\n",
    "    else:\n",
    "        if response.status_code == 429:\n",
    "            import time\n",
    "            # print(\"Sleeping 1 Sec: \" + jobId)\n",
    "            time.sleep(1)\n",
    "            trainingStartTime=get_trainingStartTime(job_Id)\n",
    "    return trainingStartTime\n",
    "\n",
    "def get_trainingEndTime(job_Id):\n",
    "    trainingEndTime=\"\"\n",
    "    body = {\"resourceNames\": [\"projects/sb-bigdata-4985-da852265\"], \"filter\":'resource.labels.task_name=\"master-replica-0\" \\\n",
    "    timestamp>=\"2019-12-12T12:43:44Z\" \\\n",
    "    Module completed'\n",
    "    }\n",
    "    y = json.dumps(body)\n",
    "    response=post_api('https://logging.googleapis.com/v2/entries:list', y)\n",
    "    import pandas as pd\n",
    "    data_df = pd.read_json(response.text)\n",
    "    if 'entries' in data_df:\n",
    "        for i in range(len(data_df['entries'])):\n",
    "            if data_df['entries'][i]['resource']['labels']['job_id'] == job_Id:\n",
    "                et = data_df['entries'][i]['timestamp']\n",
    "                # slice the timestamp to remove letters - T and Z. Also format the timestamp.\n",
    "                sliceC = et[:10]\n",
    "                startdate1=datetime.datetime.strptime(sliceC, '%Y-%m-%d').strftime('%m%d%y')\n",
    "                sliceD = et[11:26]\n",
    "                starttime1=datetime.datetime.strptime(sliceD, '%H:%M:%S.%f').strftime('%H%M%S%f')\n",
    "                # concatenate the sliced date and time segments\n",
    "                concat2 = startdate1 + starttime1\n",
    "                # format the string of timestamp\n",
    "                trainingEndTime_str=datetime.datetime.strptime(concat2, '%m%d%y%H%M%S%f').strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "                # convert string to datetime object \n",
    "                trainingEndTime=datetime.datetime.strptime(trainingEndTime_str, '%Y-%m-%d %H:%M:%S.%f')\n",
    "                break   \n",
    "    else:\n",
    "        if response.status_code == 429:\n",
    "            import time\n",
    "            # print(\"Sleeping 1 Sec: \" + jobId)\n",
    "            time.sleep(1)\n",
    "            trainingStartTime=get_trainingStartTime(job_Id)\n",
    "    return trainingEndTime\n",
    "    \n",
    "\n",
    "def get_jobs_df():\n",
    "    response = get_api('https://ml.googleapis.com/v1/projects/sb-bigdata-4985-da852265/jobs')\n",
    "    job_list=[]\n",
    "    if response.status_code == 200:\n",
    "        while True:\n",
    "            import json\n",
    "            import pandas as pd\n",
    "            data_df = pd.read_json(response.text)\n",
    "            for job in data_df['jobs']:\n",
    "                #job[\"createdby\"]=get_createdby(job[\"createTime\"], job[\"jobId\"])\n",
    "                job[\"labels\"]=[get_labels_df(job[\"createTime\"], job[\"jobId\"])]\n",
    "                #job[\"trainingCost\"]=get_cost(job[\"jobId\"])\n",
    "                #job[\"trainingStartTime\"]=get_trainingStartTime(job[\"jobId\"])\n",
    "                #job[\"trainingEndTime\"]=get_trainingEndTime(job[\"jobId\"])\n",
    "                job_list.append(job)                \n",
    "            page_token = None\n",
    "            page_token = data_df.get('nextPageToken')\n",
    "            if page_token is None:\n",
    "                break\n",
    "            else:\n",
    "                response = get_api('https://ml.googleapis.com/v1/projects/sb-bigdata-4985-da852265/jobs' + '?pageToken=' + str(page_token[0]))\n",
    "    from pandas.io.json import json_normalize\n",
    "    job_df=json_normalize(job_list)\n",
    "    job_df_new = job_df.rename(columns={\"createTime\": \"createtime\", \"endTime\": \"endtime\", \"jobId\":\"jobid\", \"startTime\":\"starttime\"\n",
    "                       , \"trainingInput.args\":\"args\", \"trainingInput.jobDir\":\"jobdir\", \"trainingInput.masterConfig.imageUri\":\"imageuri\"\n",
    "                       , \"trainingInput.masterType\":\"mastertype\", \"trainingInput.packageUris\":\"packageuris\", \"trainingInput.pythonModule\":\"pythonmodule\"\n",
    "                       , \"trainingInput.pythonVersion\":\"pythonversion\", \"trainingInput.region\":\"region\", \"trainingInput.runtimeVersion\":\"runtimeversion\"\n",
    "                       , \"trainingInput.scaleTier\":\"scaletier\", \"trainingOutput.consumedMLUnits\":\"consumedmlunits\", \"labels\":\"label\"\n",
    "                       , \"trainingInput.masterConfig.acceleratorConfig.count\":\"acceleratorconfigcount\"\n",
    "                       , \"trainingInput.masterConfig.acceleratorConfig.type\":\"acceleratorconfigtype\", \"trainingCost\":\"trainingcost\"\n",
    "                       , \"trainingStartTime\":\"trainingstarttime\", \"trainingEndTime\":\"trainingendtime\"})\n",
    "    return job_df_new\n",
    "\n",
    "def write_to_bqtable(bq_tablename, bq_schemaname, datadf):\n",
    "    import google.auth\n",
    "    from google.cloud import bigquery\n",
    "    credentials, project = google.auth.default()\n",
    "    client = bigquery.Client(project)\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    job_config.schema = bq_schemaname\n",
    "    \n",
    "    job = client.load_table_from_dataframe(datadf, bq_tablename, job_config=job_config)\n",
    "    # Wait for the load job to complete.\n",
    "    job.result()\n",
    "\n",
    "def get_data(request):\n",
    "    jobs = []\n",
    "    jobs = get_jobs_df()\n",
    "    jobs = jobs.drop(columns=[\"errorMessage\", \"etag\"])\n",
    "    print(\"AI platform jobs count : \",str(len(jobs)))\n",
    "    jobs.insert(0, 'date', str(datetime.datetime.utcnow()))\n",
    "    from google.cloud import bigquery\n",
    "    varbqschema=[\n",
    "        bigquery.SchemaField(name=\"date\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"createtime\", field_type=\"STRING\"),\n",
    "        #bigquery.SchemaField(name=\"createdby\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"endtime\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"jobid\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"starttime\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"state\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"args\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"jobdir\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"imageuri\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"mastertype\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"packageuris\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"pythonmodule\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"pythonversion\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"region\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"runtimeversion\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"scaletier\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"consumedmlunits\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"label\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"acceleratorconfigcount\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"acceleratorconfigtype\", field_type=\"STRING\"),\n",
    "        #bigquery.SchemaField(name=\"trainingcost\", field_type=\"STRING\"),\n",
    "        #bigquery.SchemaField(name=\"trainingstarttime\", field_type=\"STRING\"),\n",
    "        #bigquery.SchemaField(name=\"trainingendtime\", field_type=\"STRING\")\n",
    "    ]\n",
    "    write_to_bqtable('modelmanagement.jobmetricsnew', varbqschema, jobs.astype(str))\n",
    "    return \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.datetime.now())\n",
    "get_data(None)\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import datetime\n",
    "import json\n",
    "import google.auth\n",
    "import arrow\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from pandas.io.json import json_normalize\n",
    "import google.auth\n",
    "from google.cloud import bigquery\n",
    "from google.auth.transport.requests import AuthorizedSession\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client(location=\"US\", project=\"sb-bigdata-4985-da852265\")\n",
    "\n",
    "def get_api(url):\n",
    "    import google.auth\n",
    "    credentials, project = google.auth.default()\n",
    "    from google.auth.transport.requests import AuthorizedSession\n",
    "    authed_session = AuthorizedSession(credentials)\n",
    "    response = authed_session.get(url)\n",
    "    return response\n",
    "\n",
    "def post_api(url, data):\n",
    "    import google.auth\n",
    "    credentials, project = google.auth.default()\n",
    "    from google.auth.transport.requests import AuthorizedSession\n",
    "    authed_session = AuthorizedSession(credentials)\n",
    "    response = authed_session.post(url, data)\n",
    "    return response\n",
    "\n",
    "def get_createdby(createTime, jobId):\n",
    "    createdBy=\"NA\"\n",
    "    import arrow\n",
    "    import json\n",
    "    createTime = arrow.get(createTime)\n",
    "    logstart=createTime + datetime.timedelta(minutes = -2)\n",
    "    logend=createTime + datetime.timedelta(minutes = 2)\n",
    "    body = {\"resourceNames\": [\"projects/sb-bigdata-4985-da852265\"], \"filter\":'resource.type=\"audited_resource\" \\\n",
    "    resource.labels.service=\"ml.googleapis.com\" \\\n",
    "    resource.labels.method=\"google.cloud.ml.v1.JobService.CreateJob\" \\\n",
    "    timestamp>=\"' + str(logstart) + '\" \\\n",
    "    timestamp<=\"' + str(logend) + '\"'\n",
    "    }\n",
    "    y = json.dumps(body)\n",
    "    response=post_api('https://logging.googleapis.com/v2/entries:list', y)\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    data_df = pd.read_json(response.text)\n",
    "    if 'entries' in data_df:\n",
    "        for job in data_df['entries']:\n",
    "            if job[\"protoPayload\"][\"request\"][\"job\"][\"jobId\"] == jobId:\n",
    "                createdBy=job[\"protoPayload\"][\"authenticationInfo\"][\"principalEmail\"]\n",
    "                break\n",
    "    else:\n",
    "        if response.status_code == 429:\n",
    "            import time\n",
    "            # print(\"Sleeping 1 Sec: \" + jobId)\n",
    "            time.sleep(1)\n",
    "            createdBy=get_createdby(createTime, jobId)\n",
    "            #createdBy=\"Error\"\n",
    "            \n",
    "    return createdBy\n",
    "\n",
    "def get_labels_df(createTime, jobId):\n",
    "    labels=\"NA\"\n",
    "    import arrow\n",
    "    import pandas as pd\n",
    "    createTime = arrow.get(createTime)\n",
    "    logstart=createTime + datetime.timedelta(minutes = -2)\n",
    "    logend=createTime + datetime.timedelta(minutes = 2)\n",
    "    body = {\"resourceNames\": [\"projects/sb-bigdata-4985-da852265\"], \"filter\":'resource.type=\"audited_resource\" \\\n",
    "    resource.labels.service=\"ml.googleapis.com\" \\\n",
    "    resource.labels.method=\"google.cloud.ml.v1.JobService.CreateJob\" \\\n",
    "    timestamp>=\"' + str(logstart) + '\" \\\n",
    "    timestamp<=\"' + str(logend) + '\"'\n",
    "    }\n",
    "    y = json.dumps(body)\n",
    "    response=post_api('https://logging.googleapis.com/v2/entries:list', y)\n",
    "    data_df = pd.read_json(response.text)\n",
    "    if 'entries' in data_df:\n",
    "        for job in data_df['entries']:\n",
    "            if job[\"protoPayload\"][\"request\"][\"job\"][\"jobId\"] == jobId and \"labels\" in job[\"protoPayload\"][\"request\"][\"job\"]:\n",
    "                labels=job[\"protoPayload\"][\"request\"][\"job\"][\"labels\"]\n",
    "                break\n",
    "    else:\n",
    "        if response.status_code == 429:\n",
    "            import time\n",
    "            # print(\"Sleeping 1 Sec: \" + jobId)\n",
    "            time.sleep(1)\n",
    "            labels=get_labels_df(createTime, jobId)\n",
    "            \n",
    "    return labels\n",
    "\n",
    "def get_cost(jobId):\n",
    "    cost=\"NA\"\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    response = get_api('https://ml.googleapis.com/v1/projects/sb-bigdata-4985-da852265/jobs/')\n",
    "    data_df = pd.read_json(response.text)\n",
    "    for i in range(len(data_df['jobs'])):\n",
    "        if data_df['jobs'][i]['jobId'] == jobId:\n",
    "            cost = 0.49 * (data_df['jobs'][i]['trainingOutput']['consumedMLUnits'])\n",
    "            break\n",
    "    return cost\n",
    "\n",
    "def get_trainingStartTime(createTime, job_Id):\n",
    "    trainingStartTime=\"NA\"\n",
    "    import arrow\n",
    "    createTime = arrow.get(createTime)\n",
    "    logstart=createTime + datetime.timedelta(minutes = -2)\n",
    "    logend=createTime + datetime.timedelta(minutes = 2)\n",
    "    body = {\"resourceNames\": [\"projects/sb-bigdata-4985-da852265\"], \"filter\":'resource.labels.task_name=\"master-replica-0\" \\\n",
    "    Running task with arguments \\\n",
    "    timestamp>=\"' + str(logstart) + '\" \\\n",
    "    timestamp<=\"' + str(logend) + '\"'\n",
    "    }\n",
    "    y = json.dumps(body)\n",
    "    response=post_api('https://logging.googleapis.com/v2/entries:list', y)\n",
    "    import pandas as pd\n",
    "    data_df = pd.read_json(response.text)\n",
    "    if 'entries' in data_df:\n",
    "        for i in range(len(data_df['entries'])):\n",
    "            if data_df['entries'][i]['resource']['labels']['job_id'] == job_Id:\n",
    "                st = data_df['entries'][i]['timestamp']\n",
    "                # slice the timestamp to remove letters - T and Z. Also format the timestamp.\n",
    "                sliceA = st[:10]\n",
    "                startdate=datetime.datetime.strptime(sliceA, '%Y-%m-%d').strftime('%m%d%y')\n",
    "                sliceB = st[11:26] \n",
    "                starttime=datetime.datetime.strptime(sliceB, '%H:%M:%S.%f').strftime('%H%M%S%f')\n",
    "                # concatenate the sliced date and time segments\n",
    "                concat1 = startdate + starttime\n",
    "                # format the string of timestamp\n",
    "                trainingStartTime_str=datetime.datetime.strptime(concat1, '%m%d%y%H%M%S%f').strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "                # convert string to datetime object \n",
    "                trainingStartTime=datetime.datetime.strptime(trainingStartTime_str, '%Y-%m-%d %H:%M:%S.%f')\n",
    "                break\n",
    "    else:\n",
    "        if response.status_code == 429:\n",
    "            import time\n",
    "            # print(\"Sleeping 1 Sec: \" + jobId)\n",
    "            time.sleep(1)\n",
    "            trainingStartTime=get_trainingStartTime(createTime, job_Id)\n",
    "    return trainingStartTime\n",
    "\n",
    "# def get_trainingEndTime(createTime, job_Id):\n",
    "#     trainingEndTime=\"NA\"\n",
    "#     import arrow\n",
    "#     createTime = arrow.get(createTime)\n",
    "#     logstart=createTime + datetime.timedelta(minutes = -2)\n",
    "#     logend=createTime + datetime.timedelta(minutes = 2)\n",
    "#     body = {\"resourceNames\": [\"projects/sb-bigdata-4985-da852265\"], \"filter\":'resource.labels.task_name=\"master-replica-0\" \\\n",
    "#     Module completed cleaning up \\\n",
    "#     timestamp>=\"' + str(logstart) + '\" \\\n",
    "#     timestamp<=\"' + str(logend) + '\"'\n",
    "#     }\n",
    "#     y = json.dumps(body)\n",
    "#     response=post_api('https://logging.googleapis.com/v2/entries:list', y)\n",
    "#     import pandas as pd\n",
    "#     data_df = pd.read_json(response.text)\n",
    "#     if 'entries' in data_df:\n",
    "#         for i in range(len(data_df['entries'])):\n",
    "#             if data_df['entries'][i]['resource']['labels']['job_id'] == job_Id:\n",
    "#                 et = data_df['entries'][i]['timestamp']\n",
    "#                 # slice the timestamp to remove letters - T and Z. Also format the timestamp.\n",
    "#                 sliceC = et[:10]\n",
    "#                 enddate=datetime.datetime.strptime(sliceC, '%Y-%m-%d').strftime('%m%d%y')\n",
    "#                 sliceD = et[11:26]\n",
    "#                 endtime=datetime.datetime.strptime(sliceD, '%H:%M:%S.%f').strftime('%H%M%S%f')\n",
    "#                 # concatenate the sliced date and time segments\n",
    "#                 concat2 = enddate + endtime\n",
    "#                 # format the string of timestamp\n",
    "#                 trainingEndTime_str=datetime.datetime.strptime(concat2, '%m%d%y%H%M%S%f').strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "#                 # convert string to datetime object \n",
    "#                 trainingEndTime=datetime.datetime.strptime(trainingEndTime_str, '%Y-%m-%d %H:%M:%S.%f')\n",
    "#                 break   \n",
    "#     else:\n",
    "#         if response.status_code == 429:\n",
    "#             import time\n",
    "#             # print(\"Sleeping 1 Sec: \" + jobId)\n",
    "#             time.sleep(1)\n",
    "#             trainingEndTime=get_trainingEndTime(createTime, job_Id)\n",
    "#     return trainingEndTime\n",
    "\n",
    "#resource.labels.job_id=\"census_training_1576841019\" timestamp>=\"2019-12-20T11:23:43Z\"\n",
    "# resource.labels.job_id=\"sentiment_py3_basic_TPU_resolver_20191220_143926\" \n",
    "# jsonPayload.message=\"Module completed; cleaning up.\"\n",
    "\n",
    "def get_trainingEndTime(createTime, job_Id):\n",
    "    #print(\"START get_trainingEndTime.....\")\n",
    "    trainingEndTime=\"NA\"\n",
    "    page_token = ''\n",
    "    createTime = arrow.get(createTime)\n",
    "  \n",
    "    filter_str = 'resource.labels.job_id=\"' + str(job_Id) + '\" \\\n",
    "    jsonPayload.message=\"Module completed; cleaning up.\"'\n",
    "    body = {\"resourceNames\": [\"projects/sb-bigdata-4985-da852265\"],\"pageToken\" :str(page_token), \"filter\":filter_str }\n",
    "    #print(body)\n",
    "    y = json.dumps(body)\n",
    "    response=post_api('https://logging.googleapis.com/v2/entries:list', y)\n",
    "    #print(response.text)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        \n",
    "        while True:\n",
    "            data_df = pd.read_json(response.text, typ='series')\n",
    "            #if 'entries' in data_df:\n",
    "                #\n",
    "                #for i in range(len(data_df['entries'])):\n",
    "            if 'entries' in data_df and data_df['entries'][0]['resource']['labels']['job_id'] == job_Id:\n",
    "                et = data_df['entries'][0]['timestamp']\n",
    "                # slice the timestamp to remove letters - T and Z. Also format the timestamp.\n",
    "                sliceC = et[:10]\n",
    "                enddate=datetime.datetime.strptime(sliceC, '%Y-%m-%d').strftime('%m%d%y')\n",
    "                sliceD = et[11:26]\n",
    "                endtime=datetime.datetime.strptime(sliceD, '%H:%M:%S.%f').strftime('%H%M%S%f')\n",
    "                # concatenate the sliced date and time segments\n",
    "                concat2 = enddate + endtime\n",
    "                # format the string of timestamp\n",
    "                trainingEndTime_str=datetime.datetime.strptime(concat2, '%m%d%y%H%M%S%f').strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "                # convert string to datetime object \n",
    "                trainingEndTime=datetime.datetime.strptime(trainingEndTime_str, '%Y-%m-%d %H:%M:%S.%f')\n",
    "                #print(\"in main -->endtime for job_id {}. is {}.\".format(job_Id ,trainingEndTime))\n",
    "                break   \n",
    "            #     \n",
    "            else:\n",
    "                #\n",
    "                page_token = None\n",
    "                page_token = data_df.get('nextPageToken')\n",
    "                if page_token is None:\n",
    "                    break\n",
    "                else:\n",
    "                    #\n",
    "                    #print(\"****pagetoken recieved*****\")\n",
    "                    body = {\"resourceNames\": [\"projects/sb-bigdata-4985-da852265\"],\"pageToken\" :str(page_token), \"filter\":filter_str }\n",
    "                    y = json.dumps(body)\n",
    "                    response = post_api('https://logging.googleapis.com/v2/entries:list', y)\n",
    "\n",
    "#    print(\"END get_trainingEndTime ... \")\n",
    "    return trainingEndTime\n",
    "    \n",
    "def get_jobs_df():\n",
    "    response = get_api('https://ml.googleapis.com/v1/projects/sb-bigdata-4985-da852265/jobs')\n",
    "    job_list=[]\n",
    "    query = \"\"\"\n",
    "    SELECT MAX(createtime) \n",
    "    FROM `sb-bigdata-4985-da852265.modelmanagement.jobmetrics`;\n",
    "    \"\"\"\n",
    "    query_job = client.query(\n",
    "        query,# Location must match that of the dataset(s) referenced in the query.\n",
    "        location=\"US\")  # API request - starts the query\n",
    "    df = query_job.to_dataframe()\n",
    "    if response.status_code == 200:\n",
    "        import json\n",
    "        import pandas as pd\n",
    "        data_df = pd.read_json(response.text)\n",
    "        while True:\n",
    "            for job in data_df['jobs']:\n",
    "                #job[\"trainingStartTime\"]=get_trainingStartTime(job[\"createTime\"], job[\"jobId\"])\n",
    "                job[\"trainingEndTime\"]=get_trainingEndTime(job[\"createTime\"], job[\"jobId\"])\n",
    "                job[\"createdby\"]=get_createdby(job[\"createTime\"], job[\"jobId\"])\n",
    "                job[\"labels\"]=[get_labels_df(job[\"createTime\"], job[\"jobId\"])]\n",
    "                job[\"trainingCost\"]=get_cost(job[\"jobId\"])\n",
    "                job_list.append(job)\n",
    "                page_token = None\n",
    "                page_token = data_df.get('nextPageToken')\n",
    "                if page_token is None:\n",
    "                    break\n",
    "                else:\n",
    "                    response = get_api('https://ml.googleapis.com/v1/projects/sb-bigdata-4985-da852265/jobs' + '?pageToken=' + str(page_token[0]))\n",
    "    from pandas.io.json import json_normalize\n",
    "    job_df=json_normalize(job_list)\n",
    "    #print(job_df)\n",
    "    job_df_new = job_df.rename(columns={\"createTime\": \"createtime\", \"endTime\": \"endtime\", \"jobId\":\"jobid\", \"startTime\":\"starttime\"\n",
    "                       , \"trainingInput.args\":\"args\", \"trainingInput.jobDir\":\"jobdir\", \"trainingInput.masterConfig.imageUri\":\"imageuri\"\n",
    "                       , \"trainingInput.masterType\":\"mastertype\", \"trainingInput.packageUris\":\"packageuris\", \"trainingInput.pythonModule\":\"pythonmodule\"\n",
    "                       , \"trainingInput.pythonVersion\":\"pythonversion\", \"trainingInput.region\":\"region\", \"trainingInput.runtimeVersion\":\"runtimeversion\"\n",
    "                       , \"trainingInput.scaleTier\":\"scaletier\", \"trainingOutput.consumedMLUnits\":\"consumedmlunits\", \"labels\":\"label\"\n",
    "                       , \"trainingInput.masterConfig.acceleratorConfig.count\":\"acceleratorconfigcount\"\n",
    "                       , \"trainingInput.masterConfig.acceleratorConfig.type\":\"acceleratorconfigtype\", \"trainingCost\":\"trainingcost\"\n",
    "                       , \"trainingEndTime\":\"trainingendtime\"})\n",
    "    return job_df_new\n",
    "\n",
    "def write_to_bqtable(bq_tablename, bq_schemaname, datadf):\n",
    "    import google.auth\n",
    "    from google.cloud import bigquery\n",
    "    credentials, project = google.auth.default()\n",
    "    client = bigquery.Client(project)\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    job_config.schema = bq_schemaname\n",
    "    job = client.load_table_from_dataframe(datadf, bq_tablename, job_config=job_config)\n",
    "    # Wait for the load job to complete.\n",
    "    job.result()\n",
    "\n",
    "def get_data(request):\n",
    "    jobs = []\n",
    "    jobs = get_jobs_df()\n",
    "    jobs = jobs.drop(columns=[\"errorMessage\", \"etag\"])\n",
    "    print(\"AI platform jobs count : \",str(len(jobs)))\n",
    "    jobs.insert(0, 'date', str(datetime.datetime.utcnow()))\n",
    "    from google.cloud import bigquery\n",
    "    varbqschema=[\n",
    "        bigquery.SchemaField(name=\"date\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"createtime\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"createdby\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"endtime\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"jobid\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"starttime\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"state\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"args\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"jobdir\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"imageuri\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"mastertype\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"packageuris\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"pythonmodule\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"pythonversion\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"region\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"runtimeversion\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"scaletier\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"consumedmlunits\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"label\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"acceleratorconfigcount\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"acceleratorconfigtype\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"trainingcost\", field_type=\"STRING\"),\n",
    "        #bigquery.SchemaField(name=\"trainingstarttime\", field_type=\"STRING\"),\n",
    "        bigquery.SchemaField(name=\"trainingendtime\", field_type=\"STRING\")\n",
    "    ]\n",
    "    write_to_bqtable('modelmanagement.jobmetrics', varbqschema, jobs.astype(str))\n",
    "    return \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cost(jobId):\n",
    "    cost=\"NA\"\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    page_token = ''\n",
    "    response = get_api('https://ml.googleapis.com/v1/projects/sb-bigdata-4985-da852265/jobs/')\n",
    "    while True:\n",
    "        for i in range(len(data_df['jobs'])):\n",
    "            if data_df['jobs'][i]['jobId'] == jobId:\n",
    "                cost = 0.49 * (data_df['jobs'][i]['trainingOutput']['consumedMLUnits'])\n",
    "                print(\"s\")\n",
    "                break\n",
    "        page_token = None\n",
    "        page_token = data_df.get('nextPageToken')\n",
    "        if page_token is None:\n",
    "            print(\"t\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"u\")\n",
    "            response = get_api('https://ml.googleapis.com/v1/projects/sb-bigdata-4985-da852265/jobs' + '?pageToken=' + str(page_token[0]))\n",
    "#                 body = {\"resourceNames\": [\"projects/sb-bigdata-4985-da852265\"],\"pageToken\" :str(page_token)}\n",
    "#                 y = json.dumps(body)\n",
    "#                 response = post_api('https://ml.googleapis.com/v1/projects/sb-bigdata-4985-da852265/jobs/', y)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cost(jobId):\n",
    "    cost=\"NA\"\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    response = get_api('https://ml.googleapis.com/v1/projects/sb-bigdata-4985-da852265/jobs/')\n",
    "    if response.status_code == 200:\n",
    "        while True:\n",
    "            data_df = pd.read_json(response.text)\n",
    "            for job in data_df['jobs']:\n",
    "                if job['jobId'] == jobId:\n",
    "                    cost = 0.49 * (job['trainingOutput']['consumedMLUnits'])\n",
    "                    break\n",
    "            page_token = None\n",
    "            page_token = data_df.get('nextPageToken')\n",
    "            if page_token is None:\n",
    "                break\n",
    "            else:\n",
    "                response = get_api('https://ml.googleapis.com/v1/projects/sb-bigdata-4985-da852265/jobs' + '?pageToken=' + str(page_token[0]))\n",
    "                \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0294"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cost('census_training_1576841019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jobId': 'census_training_1577804033',\n",
       " 'trainingInput': {'packageUris': ['gs://demo-bucket-cap4985/census_job_dir/packages/88430b5e77a238e84aa76d398fa79ca79dae1583dba6bd753719e922d77495c6/census_training-0.0.0.tar.gz'],\n",
       "  'pythonModule': 'census_training.train',\n",
       "  'args': ['--bucket-name', 'demo-bucket-cap4985'],\n",
       "  'region': 'us-central1',\n",
       "  'runtimeVersion': '1.12',\n",
       "  'jobDir': 'gs://demo-bucket-cap4985/census_job_dir',\n",
       "  'pythonVersion': '3.5'},\n",
       " 'createTime': '2019-12-31T14:53:56Z',\n",
       " 'startTime': '2019-12-31T14:55:11Z',\n",
       " 'endTime': '2019-12-31T14:59:15Z',\n",
       " 'state': 'SUCCEEDED',\n",
       " 'trainingOutput': {'consumedMLUnits': 0.06},\n",
       " 'labels': {'job-tested-by': 'vaibhav-sankpal'},\n",
       " 'etag': 'y0CwIPJKnBg='}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_api('https://ml.googleapis.com/v1/projects/sb-bigdata-4985-da852265/jobs/')\n",
    "data_df = pd.read_json(response.text)\n",
    "data_df['jobs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1577456386"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost=\"NA\"\n",
    "import json\n",
    "import pandas as pd\n",
    "page_token = ''\n",
    "response = get_api('https://ml.googleapis.com/v1/projects/sb-bigdata-4985-da852265/jobs/')\n",
    "data_df = pd.read_json(response.text)\n",
    "#data_df\n",
    "page_token = data_df.get('nextPageToken')\n",
    "page_token[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "census_keras_training_27 created at: 2020-01-03T09:29:04Z\n",
      "resnet50_TPU16 created at: 2020-01-03T09:26:38Z\n",
      "sentiment_py3_CUSTOM_n1standard8_1teslaV100_2000epoch_20200103_144147 created at: 2020-01-03T09:11:51Z\n",
      "resnet50_TPU15 created at: 2020-01-03T07:30:17Z\n",
      "resnet50_TPU14 created at: 2020-01-03T06:31:59Z\n",
      "test_tpu_20200103_115835 created at: 2020-01-03T06:28:39Z\n",
      "resnet50_TPU13 created at: 2020-01-03T06:20:02Z\n",
      "test_tpu_20200103_114918 created at: 2020-01-03T06:19:22Z\n",
      "test_tpu_20200103_113032 created at: 2020-01-03T06:00:41Z\n",
      "test_tpu_20200103_111936 created at: 2020-01-03T05:49:40Z\n",
      "test_tpu_20200103_110400 created at: 2020-01-03T05:34:03Z\n",
      "test_tpu_20200103_105817 created at: 2020-01-03T05:28:21Z\n",
      "resnet50_TPU12 created at: 2020-01-02T16:14:30Z\n",
      "resnet50_TPU11 created at: 2020-01-02T16:01:50Z\n",
      "resnet50_TPU10 created at: 2020-01-02T15:47:48Z\n",
      "resnet50_TPU9 created at: 2020-01-02T15:30:05Z\n",
      "resnet50_TPU8 created at: 2020-01-02T15:08:43Z\n",
      "resnet50_TPU7 created at: 2020-01-02T14:53:02Z\n",
      "resnet50_TPU6 created at: 2020-01-02T14:38:27Z\n",
      "resnet50_TPU5 created at: 2020-01-02T14:22:33Z\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT MAX(createtime) as maxCreateTime\n",
    "FROM `sb-bigdata-4985-da852265.modelmanagement.jobmetrics`;\n",
    "\"\"\"\n",
    "query_job = client.query(\n",
    "    query,# Location must match that of the dataset(s) referenced in the query.\n",
    "    location=\"US\")  # API request - starts the query\n",
    "df = query_job.to_dataframe()\n",
    "\n",
    "response = get_api('https://ml.googleapis.com/v1/projects/sb-bigdata-4985-da852265/jobs')\n",
    "data_df = pd.read_json(response.text)\n",
    "\n",
    "for job in data_df['jobs']:\n",
    "    if job['createTime'] > df['maxCreateTime'][0]:\n",
    "        print(job['jobId'], \"created at:\", job['createTime'])\n",
    "    else:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-central1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_api('https://ml.googleapis.com/v1/projects/sb-bigdata-4985-da852265/jobs')\n",
    "data_df = pd.read_json(response.text)\n",
    "data_df['jobs'][0]['trainingInput']['region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
