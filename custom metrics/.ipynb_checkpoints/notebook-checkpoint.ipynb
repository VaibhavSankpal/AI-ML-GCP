{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import datetime\n",
    "\n",
    "def extract_last_value(machine_url):\n",
    "    str = machine_url.split(\"/\")\n",
    "    return(str[-1])    \n",
    "\n",
    "def extract_key_value(key_data,value):\n",
    "    value_data = ''\n",
    "    for i in range(len(key_data)):\n",
    "        if key_data[i]['key'] == value:\n",
    "            value_data = key_data[i]['value']\n",
    "            break\n",
    "        else:\n",
    "            value_data = ''\n",
    "    return value_data\n",
    "\n",
    "def get_api(url):\n",
    "    import google.auth\n",
    "    credentials, project = google.auth.default()\n",
    "    from google.auth.transport.requests import AuthorizedSession\n",
    "    authed_session = AuthorizedSession(credentials)\n",
    "    response = authed_session.get(url)\n",
    "    return response\n",
    "\n",
    "def get_createdby(instance_id):\n",
    "    from google.cloud import logging\n",
    "    client = logging.Client()\n",
    "    createdby = ''\n",
    "    \n",
    "    filter_str = 'resource.type=\"gce_instance\" \\\n",
    "    logName=\"projects/sb-bigdata-4985-da852265/logs/cloudaudit.googleapis.com%2Factivity\" \\\n",
    "    protoPayload.methodName=\"v1.compute.instances.insert\" \\\n",
    "    operation.first=true \\\n",
    "    protoPayload.request.disks.initializeParams.sourceImage:\"projects/deeplearning-platform-release/global/images/family/\" \\\n",
    "    resource.labels.instance_id=\"' + str(instance_id) + '\"'\n",
    "    \n",
    "    for entry in client.list_entries(filter_=filter_str):  # API call(s)\n",
    "        from chardet import detect\n",
    "        payloaddata = entry.payload.value.decode('cp1254', errors='ignore').split('@accenture.com')[0]\n",
    "        import re\n",
    "        createdby = re.sub(r\"[^a-z0-9.]\",\"\",payloaddata.lower())\n",
    "    \n",
    "    return createdby\n",
    "    \n",
    "def get_notebooks_df(notebook_data_df):\n",
    "    framework = [] # list\n",
    "    name = [] # list\n",
    "    instance_id = []\n",
    "    created_at = []\n",
    "    label = []\n",
    "    status = []\n",
    "    machine_type = []\n",
    "    sa_account = []\n",
    "    proxy_mode = []\n",
    "    proxy_user_email = []\n",
    "    gpu_name = []\n",
    "    zone=[]\n",
    "    network = []\n",
    "    subnetwork = []\n",
    "    bootdisksize=[]\n",
    "    bootdisktype=[]\n",
    "    created_by=[]\n",
    "    \n",
    "    for i in range(0,len(notebook_data_df)):\n",
    "         #print(notebook_data_df[i])\n",
    "        notebook_data_df[i]['machineType']\n",
    "        name.append(str(notebook_data_df[i]['name']))\n",
    "        instance_id.append(notebook_data_df[i]['id'])\n",
    "        created_at.append(notebook_data_df[i]['creationTimestamp'])\n",
    "        created_by.append(get_createdby(notebook_data_df[i]['id']))\n",
    "        machine_type.append(extract_last_value(notebook_data_df[i]['machineType']))\n",
    "        zone.append(extract_last_value(notebook_data_df[i]['zone']))\n",
    "        network.append(extract_last_value(notebook_data_df[i]['networkInterfaces'][0]['network']))\n",
    "        subnetwork.append(extract_last_value(notebook_data_df[i]['networkInterfaces'][0]['subnetwork']))\n",
    "        labels = notebook_data_df[i].get('labels')\n",
    "        label.append(labels)\n",
    "        status.append(notebook_data_df[i]['status'])\n",
    "        sa_account.append(notebook_data_df[i]['serviceAccounts'][0]['email'])\n",
    "        proxy_mode.append(extract_key_value(notebook_data_df[i]['metadata']['items'],'proxy-mode'))\n",
    "        proxy_user_email.append(extract_key_value(notebook_data_df[i]['metadata']['items'],'proxy-user-mail'))\n",
    "        framework.append(extract_key_value(notebook_data_df[i]['metadata']['items'],'framework'))\n",
    "        #gpu_names = notebook_data_df[i].get('guestAccelerators')[0]['acceleratorType']\n",
    "        notebook_gpu_name = ''\n",
    "        gpu_names = ''\n",
    "        gpu_names = notebook_data_df[i].get('guestAccelerators')\n",
    "        if gpu_names is not None:\n",
    "            notebook_gpu_name = gpu_names[0]['acceleratorType']\n",
    "        gpu_name.append(extract_machine_type(notebook_gpu_name))\n",
    "        bootdisk_url = notebook_data_df[i]['disks'][0]['source']\n",
    "        response = get_api(bootdisk_url)\n",
    "        import json\n",
    "        data_df = json.loads(response.text)\n",
    "        bootdisksize.append(data_df['sizeGb'])\n",
    "        bootdisktype.append(extract_last_value(data_df['type']))\n",
    "        \n",
    "        \n",
    "        import pandas as pd\n",
    "        notebook_list = pd.DataFrame(\n",
    "            {'name': name,\n",
    "             'instanceid':instance_id,\n",
    "             'zone': zone,\n",
    "             'network': network,\n",
    "             'subnetwork': subnetwork,\n",
    "             'createdat':created_at,\n",
    "             'createdby':created_by,\n",
    "             'machinetype' : machine_type,\n",
    "             'label': label,\n",
    "             'status' : status,\n",
    "             'serviceaccount' : sa_account,\n",
    "             'proxymode':proxy_mode,\n",
    "             'proxyuseremail':proxy_user_email,\n",
    "             'framework': framework,\n",
    "             'gpu':gpu_name,\n",
    "             'bootdisksize':bootdisksize,\n",
    "             'bootdisktype':bootdisktype\n",
    "            },\n",
    "            columns=['name', 'instanceid', 'zone','network','subnetwork', 'createdat','createdby','machinetype','label','status','serviceaccount','proxymode','proxyuseremail','framework','gpu', 'bootdisksize', 'bootdisktype']\n",
    "        )\n",
    "    return notebook_list\n",
    "\n",
    "def write_to_bqtable(bq_tablename, bq_schemaname, datadf):\n",
    "    import google.auth\n",
    "    from google.cloud import bigquery\n",
    "    credentials, project = google.auth.default()\n",
    "    client = bigquery.Client(project)\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    job_config.schema = bq_schemaname\n",
    "    \n",
    "    job = client.load_table_from_dataframe(datadf, bq_tablename, job_config=job_config)\n",
    "    # Wait for the load job to complete.\n",
    "    job.result()\n",
    "\n",
    "def get_data(request): \n",
    "    notebook = []\n",
    "    response = get_api('https://compute.googleapis.com/compute/v1/projects/sb-bigdata-4985-da852265/aggregated/instances?filter=tags.tag%20:%20deeplearning-vm')\n",
    "    if response.status_code == 200:\n",
    "        import json\n",
    "        import pandas as pd\n",
    "        data_df = pd.read_json(response.text)\n",
    "        from pandas.io.json import json_normalize  \n",
    "        json_norm = json_normalize(data_df['items'])\n",
    "        na_data = json_norm[json_norm['instances'].notna()]\n",
    "        for value in na_data['instances']:\n",
    "            for instance_data in value:\n",
    "                notebook.append(instance_data)\n",
    "        print(\"AI platform notebook count : \",str(len(notebook)))\n",
    "        notebook = get_notebooks_df(notebook)\n",
    "        notebook.insert(0, 'date', str(datetime.datetime.utcnow()))\n",
    "        from google.cloud import bigquery\n",
    "        varbqschema=[\n",
    "            bigquery.SchemaField(name=\"date\", field_type=\"STRING\"),\n",
    "            bigquery.SchemaField(name=\"name\", field_type=\"STRING\"),\n",
    "            bigquery.SchemaField(name=\"instanceid\", field_type=\"STRING\"),\n",
    "            bigquery.SchemaField(name=\"zone\", field_type=\"STRING\"),\n",
    "            bigquery.SchemaField(name=\"network\", field_type=\"STRING\"),\n",
    "            bigquery.SchemaField(name=\"subnetwork\", field_type=\"STRING\"),\n",
    "            bigquery.SchemaField(name=\"createdat\", field_type=\"STRING\"),\n",
    "            bigquery.SchemaField(name=\"createdby\", field_type=\"STRING\"),\n",
    "            bigquery.SchemaField(name=\"machinetype\", field_type=\"STRING\"),\n",
    "            bigquery.SchemaField(name=\"label\", field_type=\"STRING\"),\n",
    "            bigquery.SchemaField(name=\"status\", field_type=\"STRING\"),\n",
    "            bigquery.SchemaField(name=\"serviceaccount\", field_type=\"STRING\"),\n",
    "            bigquery.SchemaField(name=\"proxymode\", field_type=\"STRING\"),\n",
    "            bigquery.SchemaField(name=\"proxyuseremail\", field_type=\"STRING\"),\n",
    "            bigquery.SchemaField(name=\"framework\", field_type=\"STRING\"),\n",
    "            bigquery.SchemaField(name=\"gpu\", field_type=\"STRING\"),\n",
    "            bigquery.SchemaField(name=\"bootdisksize\", field_type=\"STRING\"),\n",
    "            bigquery.SchemaField(name=\"bootdisktype\", field_type=\"STRING\")\n",
    "        ]\n",
    "        write_to_bqtable('modelmanagement.notebooks', varbqschema, notebook.astype(str))\n",
    "    else:\n",
    "        print(response.text)\n",
    "    return \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI platform notebook count :  9\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'extract_machine_type' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-92da8bf58e92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnotebook_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnotebook_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-2e0a92266f1f>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mnotebook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AI platform notebook count : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mnotebook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_notebooks_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mnotebook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbigquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-2e0a92266f1f>\u001b[0m in \u001b[0;36mget_notebooks_df\u001b[0;34m(notebook_data_df)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgpu_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mnotebook_gpu_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpu_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acceleratorType'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mgpu_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_machine_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotebook_gpu_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mbootdisk_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnotebook_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'disks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbootdisk_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'extract_machine_type' is not defined"
     ]
    }
   ],
   "source": [
    "notebook_list = get_data(None)\n",
    "notebook_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
